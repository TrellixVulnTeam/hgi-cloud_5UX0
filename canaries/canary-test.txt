# ----------------------------------------------------------------------------
# Copy & Paste the following on the command line
# ----------------------------------------------------------------------------
declare -a _JARS=(
  "${HAIL_HOME}/build/libs/hail-all-spark.jar"
  "${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-core-1.10.6.jar"
  "${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-kms-1.10.6.jar"
  "${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-s3-1.10.6.jar"
  "${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-aws-2.8.2.jar"
)
export HAIL_SESSION="$(mktemp --directory /tmp/hail.XXXXXXXXXX)"
echo ${HAIL_SESSION}
/opt/sanger.ac.uk/hgi/anaconda3/bin/pyspark \
  --jars "$(IFS=, ; echo "${_JARS[*]}")" \
  --conf "spark.driver.extraJavaOptions=-Dderby.system.home=${HAIL_SESSION}" \
  --conf "spark.driver.extraClassPath=${HAIL_HOME}/build/libs/hail-all-spark.jar" \
  --conf "spark.executor.extraClassPath=${HAIL_HOME}/build/libs/hail-all-spark.jar" \
  --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
  --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator

# ----------------------------------------------------------------------------
# Copy & Paste the following in the interactive python shell opened by the
# pyspark command.
# ----------------------------------------------------------------------------
import os
import hail

app_name = 'canary'
hail.init(app_name=app_name)

mt = hail.balding_nichols_model(n_populations=3, n_samples=50, n_variants=100)
mt.count()

hadoop_config = sc._jsc.hadoopConfiguration()
hadoop_config.set('fs.s3a.access.key', '8YY584J59H7Q6AVKHSU8')
hadoop_config.set('fs.s3a.secret.key', 'P8vePa7JUvxKXX2me9ti1cGujgYWMoimAwx4mMlM')
mt = hail.import_vcf('s3a://1kg/1kg.vcf.bgz')
mt.describe()
mt.count()
