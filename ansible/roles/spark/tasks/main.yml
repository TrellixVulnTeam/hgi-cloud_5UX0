---
- name: Set spark_home fact
  set_fact:
    spark_home: "{{ spark_install_dir }}/spark-{{ spark_version }}"

- name: Ensure Scala is installed
  apt:
    state: present
    name:
      - scala

- name: Create group account for Spark
  group:
    state: present
    name: "{{ spark_group_name }}"
    gid: "{{ spark_group_gid }}"
  tags: ["spark-group"]

- name: Create user account for Spark
  user:
    state: present
    name: "{{ spark_user_name }}"
    uid: "{{ spark_user_uid }}"
    group: "{{ spark_group_gid }}"
    system: no
    home: "{{ spark_home }}"
    create_home: no
    shell: "{{ spark_user_shell }}"
    groups: "{{ spark_user_groups | join(',') }}"
  tags: ["spark-user"]

- name: Ensure Spark download, source and install directories exist
  file:
    state: directory
    path: "{{ item }}"
    mode: 0775
    follow: true
  with_items:
    - "{{ spark_download_dir }}"
    - "{{ spark_install_dir }}"

- name: Download Spark distribution
  get_url:
    url: "{{ spark_mirror }}/spark-{{ spark_version }}/spark-{{ spark_version }}.tgz"
    dest: "{{ spark_download_dir }}/spark-{{ spark_version }}.tgz"

# TODO: This should really be implemented
#
# - name: Verify downloaded Spark distribution
#   command: /bin/true

- name: Extract Spark distribution
  unarchive:
    src: "{{ spark_download_dir }}/spark-{{ spark_version }}.tgz"
    dest: "{{ spark_install_dir }}"
    copy: no
    owner: "{{ spark_install_owner }}"
    group: "{{ spark_install_group }}"
    mode: "u+rw,go+r"
    creates: "{{ spark_home }}"

- name: Ensure Spark conf, log, run, temp and work directories exist
  file:
    state: directory
    path: "{{ spark_home }}/{{ spark_dir }}"
    owner: "{{ spark_user_name }}"
    group: "{{ spark_group_name }}"
    mode: 0775
  loop:
    - log
    - run
    - temp
    - work
    - conf
  loop_control:
    loop_var: spark_dir

- name: Ensure Spark local directories exist
  file:
    state: directory
    path: "{{ local_dir }}"
    owner: "{{ spark_local_owner }}"
    group: "{{ spark_local_group }}"
    mode: "{{ spark_local_mode }}"
  when: local_dir != "/tmp"
  loop: "{{ spark_local_dirs }}"
  loop_control:
    loop_var: local_dir
  tags: ["spark-local-dirs"]

- name: Configure Spark environment
  template:
    src: spark-env.sh.j2
    dest: "{{ spark_home }}/conf/spark-env.sh"
  tags: ["config"]

- name: Configure Spark defaults config file
  template:
    src: spark-defaults.conf.j2
    dest: "{{ spark_home }}/conf/spark-defaults.conf"
  tags: ["config"]

- name: Deploy Spark log4j properties
  template:
    src: log4j.properties.j2
    dest: "{{ spark_home }}/conf/log4j.properties"
    owner: "{{ spark_user_name }}"
    group: "{{ spark_group_name }}"

- name: Create symlink to Spark versioned installation directory
  file:
    state: link
    path: "{{ spark_install_dir }}/spark"
    src: "{{ spark_home }}"

- name: Tune sysctl parameters for spark
  become: yes
  sysctl:
    state: present
    name: "{{ param.name }}"
    value: "{{ param.value }}"
    sysctl_file: /etc/sysctl.conf
  loop: "{{ spark_sysctl_params }}"
  loop_control:
    loop_var: param
