---
- name: Initiate a new docker-swarm 
  docker_swarm:
    state: present
    register: docker_swarm_facts
- debug:
    var: docker_swarm_facts
    var: docker_swarm_facts.swarm_facts.JoinTokens
    # advertise_addr: If advertise_addr is not specified, it will be automatically detected when possible.



# - name: Ensure deprecated Docker packages are absent
#   apt:
#     state: absent
#     name:
#       - docker
#       - docker-engine
#       - docker.io
#       - containerd
#       - runc
#     force_apt_get: true

# - name: Add Docker APT repository key
#   apt_key:
#     state: present
#     url: https://download.docker.com/linux/ubuntu/gpg

# - name: Add Docker APT repository
#   apt_repository:
#     state: present
#     repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_lsb['codename'] }} stable"

# - name: Create Docker configuration directory
#   file:
#     state: directory
#     path: /etc/docker

# - name: Pre-configure Docker daemon
#   template:
#     src: daemon.json.j2
#     dest: /etc/docker/daemon.json

# - name: Ensure Docker is installed
#   apt:
#     state: present
#     update_cache: true
#     name:
#       - apt-transport-https
#       - ca-certificates
#       - curl
#       - gnupg-agent
#       - software-properties-common
#       - docker-ce
#       - docker-ce-cli
#       - containerd.io
#     install_recommends: true
#     force_apt_get: true

# - name: Ensure python docker module is istalled
#   pip:
#     name: docker
#     state: present

# - name: Ensure base user belongs to the docker group
#   user:
#     name: "{{ base_user_name }}"
#     groups:
#       - docker


# - name: Configure Spark environment
#   template:
#     src: spark-env.sh.j2
#     dest: "{{ spark_home }}/conf/spark-env.sh"
#     owner: "{{ spark_user_name }}"
#     group: "{{ spark_group_name }}"
#   tags: ["config"]

# - name: Configure Spark defaults
#   template:
#     src: spark-defaults.conf.j2
#     dest: "{{ spark_home }}/conf/spark-defaults.conf"
#     owner: "{{ spark_user_name }}"
#     group: "{{ spark_group_name }}"
#   tags: ["config"]

# - name: Configure Spark log4j properties
#   template:
#     src: log4j.properties.j2
#     dest: "{{ spark_home }}/conf/log4j.properties"
#     owner: "{{ spark_user_name }}"
#     group: "{{ spark_group_name }}"

# - name: Setup Spark local dirs
#   file:
#     state: directory
#     path: "{{ local_dir }}"
#     owner: "{{ spark_install_owner }}"
#     group: "{{ spark_install_group }}"
#     mode: "{{ spark_install_mode }}"
#   loop: "{{ spark_local_dirs }}"
#   loop_control:
#     loop_var: local_dir

# - name: Tune sysctl parameters for Spark
#   become: yes
#   sysctl:
#     state: present
#     name: "{{ param.name }}"
#     value: "{{ param.value }}"
#     sysctl_file: /etc/sysctl.conf
#   loop: "{{ spark_sysctl_params }}"
#   loop_control:
#     loop_var: param

# - name: Install Spark services
#   template:
#     src: "spark.service.j2"
#     dest: "/etc/systemd/system/spark-{{ service }}.service"
#     owner: root
#   become: yes
#   loop:
#     - master
#     - slave
#   loop_control:
#     loop_var: service



# ---
# - name: Enable and start spark-master service
#   become: yes
#   service:
#     name: spark-master
#     enabled: yes
#     state: started
