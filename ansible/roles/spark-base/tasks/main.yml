---
- name: Ensure Scala and R are installed
  apt:
    state: present
    name:
      - scala
      - r-base
      - r-recommended
      - libopenblas-base
      - libatlas3-base
      - libnetlib-java
      - liblz4-dev
      - nfs-common
    install_recommends: true
    force_apt_get: true

- name: Ensure group account for Spark exists
  group:
    state: present
    name: "{{ spark_group_name }}"

- name: Ensure user account for Spark exists
  user:
    state: present
    name: "{{ spark_user_name }}"

- name: Ensure Spark download, source and install directories exist
  file:
    state: directory
    path: "{{ spark_build_dir }}"
    owner: "{{ spark_user_name }}"
    group: "{{ spark_group_name }}"
    mode: 0775
    follow: true
  loop:
    - "{{ spark_download_dir }}"
    - "{{ spark_install_dir }}"
    - "{{ spark_source_dir }}"
  loop_control:
    loop_var: spark_build_dir

- name: Download Spark distribution
  get_url:
    url: "{{ spark_distribution_url }}"
    dest: "{{ spark_download_dir }}/{{ spark_distribution_basename }}.tgz"

- name: Extract Spark distribution
  unarchive:
    src: "{{ spark_download_dir }}/{{ spark_distribution_basename }}.tgz"
    dest: "{{ spark_install_dir }}"
    copy: no
    owner: "{{ spark_install_owner }}"
    group: "{{ spark_install_group }}"
    mode: "{{ spark_install_mode }}"
    creates: "{{ spark_home }}"

- name: Ensure Spark runtime directories exist
  file:
    state: directory
    path: "{{ spark_runtime_dir }}"
    owner: "{{ spark_install_owner }}"
    group: "{{ spark_install_group }}"
    mode: "{{ spark_install_mode }}"
  loop:
    - "{{ spark_pid_dir }}"
    - "{{ spark_log_dir }}"
    - "{{ spark_work_dir }}"
    - "{{ spark_conf_dir }}"
  loop_control:
    loop_var: spark_runtime_dir

- name: Ensure Spark local directories exist
  file:
    state: directory
    path: "{{ local_dir }}"
    owner: "{{ spark_install_owner }}"
    group: "{{ spark_install_group }}"
    mode: "{{ spark_install_mode }}"
  when: local_dir != "/tmp"
  loop: "{{ spark_local_dirs }}"
  loop_control:
    loop_var: local_dir
  tags: ["spark-local-dirs"]

- name: Create symlink to Spark versioned installation directory
  file:
    state: link
    path: "{{ spark_install_dir }}/spark"
    src: "{{ spark_home }}"

- name: Configure system-wide environment variables
  template:
    src: profile.sh.j2
    dest: /etc/profile.d/30-spark.sh
